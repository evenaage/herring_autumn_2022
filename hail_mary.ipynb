{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "import netCDF4\n",
    "import util.ml_util as ut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8549, 14) (9245, 14) (7808, 14)\n",
      "1251\n",
      "0.1244590010527547\n",
      "0.4389781739069408\n"
     ]
    }
   ],
   "source": [
    "jan_2020_data, jan_2020_target = ut.load_and_combine_data(2020, 'jan','dataset_1_closest_grid_cells', skip_bad_cells=True)\n",
    "jan_2019_data, jan_2019_target = ut.load_and_combine_data(2019, 'jan','dataset_1_closest_grid_cells', skip_bad_cells=True)\n",
    "jan_2021_data, jan_2021_target = ut.load_and_combine_data(2021, 'jan','dataset_1_closest_grid_cells', skip_bad_cells=True)\n",
    "dec_2020_data, dec_2020_target = ut.load_and_combine_data(2020, 'dec','dataset_1_closest_grid_cells', skip_bad_cells=True)\n",
    "sc = StandardScaler()\n",
    "jan_2020_data = sc.fit_transform(jan_2020_data)\n",
    "jan_2019_data = sc.fit_transform(jan_2019_data)\n",
    "jan_2021_data = sc.fit_transform(jan_2021_data)\n",
    "dec_2020_data = sc.fit_transform(dec_2020_data)\n",
    "print(jan_2020_data.shape, jan_2019_data.shape, jan_2021_data.shape, dec_2020_data.shape)\n",
    "#jan_2019_target +=1\n",
    "#jan_2019_target = np.log(jan_2019_target)\n",
    "#jan_2020_target +=1\n",
    "#jan_2020_target = np.log(jan_2020_target)\n",
    "#onzero_indices2019 = jan_2019_target[jan_2019_target ==1]\n",
    "#zero_indices2020 = jan_2020_target[jan_2020_target ==0]\n",
    "\n",
    "\n",
    "jan_2019_target = np.array([1 if i > 0  else 0 for i in jan_2019_target ])\n",
    "jan_2020_target = np.array([1 if i > 0  else 0 for i in jan_2020_target ])\n",
    "jan_2021_target = np.array([1 if i > 0  else 0 for i in jan_2021_target ])\n",
    "dec_2020_target = np.array([1 if i > 0  else 0 for i in dec_2020_target ])\n",
    "\n",
    "nonzero_data = jan_2019_data[jan_2019_target >0]\n",
    "print(len(nonzero_data))\n",
    "nonzero_targets = jan_2019_target[jan_2019_target >0]\n",
    "for i in range(4):\n",
    "    jan_2019_data = np.append(jan_2019_data, nonzero_data, axis = 0)\n",
    "    jan_2019_target = np.append(jan_2019_target, nonzero_targets, axis = 0)\n",
    "\n",
    "print(np.count_nonzero(jan_2020_target) /len(jan_2020_target))\n",
    "print(np.count_nonzero(jan_2019_target)/len(jan_2019_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 14\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        #self.do = nn.Dropout(.3)\n",
    "        self.fc4 = nn.Linear(64,32)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.sigmoid(self.fc5(x))\n",
    "        #x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "class simpleNet(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, 512)\n",
    "        self.fc2 = nn.Linear(512, input_shape)\n",
    "        self.fc3 = nn.Linear(input_shape, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emperature = netCDF4.Dataset(ut.localize_nc_file('nor4km_data', 2021, 1, 5))['temperature'][12,0,:,:]\n",
    "#print(temperature.shape)\n",
    "#ut.print_on_map(temperature)\n",
    "model = torch.load('pytorch_model')\n",
    "pred = model(torch.tensor(jan_2021_data, dtype=torch.float32)).detach().numpy()\n",
    "ut.validate(model,pred, jan_2021_target,.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC_LOW = 41 #41\n",
    "YC_LOW = 157 # 157\n",
    "XC_HIGH = 671# 671\n",
    "YC_HIGH = 373 #\n",
    "model = torch.load('pytorch_model')\n",
    "VARIABLES = ['temperature','salinity','u_east', 'v_north',  'w_north', 'w_east']\n",
    "nc = netCDF4.Dataset(ut.localize_nc_file('nor4km_data',2021, 1,20 ))\n",
    "data = ut.get_relevant_data_nc(nc,VARIABLES,12)\n",
    "plankton = netCDF4.Dataset(ut.localize_plankton_file('plankton_data', 2021, 1, 20))['Calanus_finmarchicus']\n",
    "#print(data.shape, plankton.shape)\n",
    "data = np.append(data, plankton, axis=0)\n",
    "\n",
    "grads = []\n",
    "for i in range(len(VARIABLES) +1):\n",
    "    grad = np.gradient(data[i,:,:])\n",
    "    grad = np.sqrt(np.square(grad[0].data) + np.square(grad[0].data))\n",
    "    grads.append(grad)\n",
    "#print(data.shape, np.array(grads).shape)\n",
    "data = np.append(data, grads, axis = 0)\n",
    "#data = np.reshape(data, (-1,14))\n",
    "#print(data.shape)\n",
    "#prediction = model(torch.tensor(data,dtype=torch.float32)).detach().numpy()\n",
    "#prediction = prediction.reshape(1,620,941)\n",
    "pred = np.zeros((620, 941))\n",
    "for xc in range(XC_LOW, XC_HIGH):\n",
    "    if xc % 100 ==0: print(xc)\n",
    "    for yc in range(YC_LOW, YC_HIGH):\n",
    "        val = 1 if  model(torch.tensor(data[:,yc, xc],dtype=torch.float32)).detach().numpy()[0] > 0 else 0\n",
    "        pred[yc, xc] =val\n",
    "        #if val > 0:print(val)\n",
    "print(np.count_nonzero(pred))\n",
    "ut.print_on_map(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLES = ['temperature','salinity','u_east', 'v_north',  'w_north', 'w_east']\n",
    "nc = netCDF4.Dataset(ut.localize_nc_file('nor4km_data',2021, 1,20 ))\n",
    "data = ut.get_relevant_data_nc(nc,VARIABLES,12)\n",
    "y, x =np.where(pred > .2)\n",
    "mask = data[0,...].mask\n",
    "print(mask)\n",
    "masked = np.array([mask[y[i], x[i]] for i in range(len(y))])\n",
    "print(np.count_nonzero(masked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .001\n",
    "epochs = 300\n",
    "model = Net(input_shape=jan_2019_data.shape[1])\n",
    "#model = simpleNet(input_shape=jan_2019_data.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "#loss_fn = nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class dataset(Dataset):\n",
    "  def __init__(self,x,y):\n",
    "    self.x = torch.tensor(x,dtype=torch.float32)\n",
    "    self.y = torch.tensor(y,dtype=torch.float32)\n",
    "    self.length = self.x.shape[0]\n",
    " \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x[idx],self.y[idx]\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "trainset = dataset(jan_2019_data,jan_2019_target)\n",
    "#DataLoader\n",
    "trainloader = DataLoader(trainset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accur = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "for i in range(epochs):\n",
    "  for j,(x_train,y_train) in enumerate(trainloader):\n",
    "    \n",
    "    #calculate output\n",
    "    output = model(x_train)\n",
    "    #if j == 0:print(output)\n",
    "    #calculate loss\n",
    "    loss = loss_fn(output,y_train.reshape(-1,1))\n",
    " \n",
    "    #accuracy\n",
    "    predicted = model(torch.tensor(jan_2019_data,dtype=torch.float32))\n",
    "    acc = (predicted.reshape(-1).detach().numpy().round() == jan_2019_target).mean()\n",
    "    #backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  if i%10 == 0:\n",
    "    losses.append(loss)\n",
    "    accur.append(acc)\n",
    "    #print(y_train.shape, output.shape)\n",
    "    output = model(torch.tensor(jan_2020_data,dtype=torch.float32))\n",
    "    target = torch.tensor(jan_2020_target,dtype=torch.float32)\n",
    "    _loss = loss_fn(output, target[:,None])\n",
    "    _acc = (output.reshape(-1).detach().numpy().round() == jan_2020_target).mean()\n",
    "    print(\"epoch {}\\tloss : {}\\t accuracy : {}\".format(i,loss,acc))\n",
    "    print(\"loss on test set: \", _loss, ' Acc on test set: ', _acc)\n",
    "    valid_loss.append(_loss)\n",
    "    valid_acc.append(_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(jan_2020_data)\n",
    "#print(model(torch.tensor(jan_2020_data, dtype=torch.float32)))\n",
    "predicted = model(torch.tensor(jan_2020_data,dtype=torch.float32))\n",
    "acc = (predicted.reshape(-1).detach().numpy().round() == jan_2020_target).mean()\n",
    "print(acc)\n",
    "print(predicted.shape, torch.tensor(jan_2020_target.shape, dtype=torch.float32))\n",
    "print(predicted)\n",
    "loss = loss_fn(predicted.reshape(1,-1), torch.tensor(jan_2020_target.reshape(1,-1)))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the loss\n",
    "losses = [l.data for l in losses]\n",
    "valid_loss = [l.data for l in valid_loss]\n",
    "plt.plot([i*10 for i in range(30)], losses)\n",
    "plt.plot([i*10 for i in range(30)],valid_loss )\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('BCELoss')\n",
    "plt.legend(['training_set', 'validation_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the accuracy\n",
    "plt.plot( [i*10 for i in range(30)],accur)\n",
    "plt.plot([i*10 for i in range(30)],valid_acc)\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training_set', 'validation_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'pytorch_model_300_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(torch.tensor(jan_2021_data, dtype=torch.float32)).detach().numpy()\n",
    "pred = [1 if p > .2 else 0 for p in pred]\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(jan_2021_target,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(torch.tensor(jan_2021_data, dtype=torch.float32)).detach().numpy()\n",
    "cutoffs = [.5 + .025*i for i in range(10)]\n",
    "print(cutoffs)\n",
    "pred =[ [1 if p > c else 0 for p in pred] for c in cutoffs]\n",
    "acc = []\n",
    "sens = []\n",
    "spec = []\n",
    "all_pos = np.count_nonzero(jan_2021_target)\n",
    "for p in pred:\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    acc.append(np.array([p == jan_2021_target]).mean())\n",
    "    for i in range(len(p)):\n",
    "        if jan_2021_target[i] == 1:\n",
    "            if p[i] == 1: \n",
    "                true_pos += 1\n",
    "                pos += 1\n",
    "            else: neg += 1\n",
    "        else :\n",
    "            if p[i] == 1:\n",
    "                pos += 1\n",
    "            else:\n",
    "                neg += 1\n",
    "                true_neg += 1\n",
    "   # positives = [_p == 1 for _p in p]\n",
    "    #negatives = [_p == 0 for _p in p]\n",
    "    #true_positives = [x == 1 for x in jan_2020_target]\n",
    "    #true_negatives = [x == 0 for x in jan_2020_target]\n",
    "    #_sens = np.array([1 if positives[i] == true_positives[i] else 0 for i in range(len(positives))]).mean()\n",
    "    #_spec = np.array([1 if negatives[i] == true_negatives[i] else 0 for i in range(len(negatives))]).mean()\n",
    "    sens.append(true_pos/all_pos)\n",
    "    spec.append(true_neg/ (len(jan_2021_target) - all_pos))\n",
    "#pred = [np.array([p == jan_2020_target]).mean() for p in pred]\n",
    "#print(pred)\n",
    "#print(accuracy)\n",
    "print([.5 + .025*i for i in range(10)],sens)\n",
    "print([.5 + .025*i for i in range(10)],spec)\n",
    "print([.5 + .025*i for i in range(10)],acc)\n",
    "plt.xlabel(\"probability cutoff\")\n",
    "#metrics.ConfusionMatrixDisplay.from_predictions(jan_2020_target,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([.5 + .025*i for i in range(10)],sens)\n",
    "plt.plot([.5 + .025*i for i in range(10)],spec)\n",
    "plt.plot([.5 + .025*i for i in range(10)],acc)\n",
    "plt.legend(['Sensitivity',' Specificity','Accuracy'])\n",
    "plt.xlabel(\"Probability cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble.AdaBoostClassifier(n_estimators=1000, learning_rate = .001)\n",
    "model.fit(jan_2019_data, jan_2019_target)\n",
    "r_sq = model.score(jan_2019_data, jan_2019_target)\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(jan_2020_target,model.predict(jan_2020_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'pytorch_model_5k_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 19.0.1+10-21, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\evenasm\\Documents\\sild_h√∏st_2022\\.venv\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\evenasm\\AppData\\Local\\Temp\\tmp36zxjqsf\n",
      "  JVM stdout: C:\\Users\\evenasm\\AppData\\Local\\Temp\\tmp36zxjqsf\\h2o_evenasm_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\evenasm\\AppData\\Local\\Temp\\tmp36zxjqsf\\h2o_evenasm_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Oslo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.38.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 8 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_evenasm_35efkg</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.953 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.8 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Europe/Oslo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.38.0.2\n",
       "H2O_cluster_version_age:    1 month and 8 days\n",
       "H2O_cluster_name:           H2O_from_python_evenasm_35efkg\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.953 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.8 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import sklearn\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "#h2o.shutdown()\n",
    "h2o.init(log_level='FATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Temperature',  'Salinity', 'u_east', 'v_north',  'w_north', 'w_east','Temperature gradient', \\\n",
    "     'Salinity gradient','w_east_gradient', 'u_east gradient','v_north_gradient','w_north_gradient','Calanus finmarchicus', \\\n",
    "        'Calanus finmarchicus gradient', 'Catch']\n",
    "x_vars =  ['Temperature',  'Salinity', 'u_east', 'v_north',  'w_north', 'w_east','Temperature gradient', \\\n",
    "     'Salinity gradient','w_east_gradient', 'u_east gradient','v_north_gradient','w_north_gradient','Calanus finmarchicus', \\\n",
    "        'Calanus finmarchicus gradient']\n",
    "        \n",
    "training = np.append(jan_2019_data, np.expand_dims(jan_2019_target,1), axis=1)\n",
    "training = np.append(dec_2020_data,np.expand_dims(dec_2020_target,1), axis=1)\n",
    "valid = np.append(jan_2020_data, np.expand_dims(jan_2020_target,1), axis=1)\n",
    "train = h2o.H2OFrame(training,column_names =names)\n",
    "valid = h2o.H2OFrame(valid, column_names = names)\n",
    "print(train.head())\n",
    "train['Catch'] = train['Catch'].asfactor()\n",
    "valid['Catch'] = valid['Catch'].asfactor()\n",
    "\n",
    "jan_2021_data_aml = h2o.H2OFrame(np.append(jan_2021_data, np.expand_dims(jan_2021_target,1), axis=1), column_names = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml= H2OAutoML(max_models=10, seed=1, balance_classes = True,nfolds = 0)\n",
    "aml.train(x=x_vars, y='Catch',training_frame=train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = aml.predict(jan_2021_data_aml).as_data_frame().to_numpy()\n",
    "#pred = aml.predict(jan_2021_data_aml).as_data_frame().to_numpy()\n",
    "#print(jan_2021_data_aml.head())\n",
    "#print(len(pred['predict']))\n",
    "#print(pred['predict'].shape)\n",
    "#pred = np.reshape(np.array(pred['predict']), (1,-1))\n",
    "#print(pred[pred > 0])\n",
    "print(pred.shape)\n",
    "pred = pred[:,0]\n",
    "print(type(pred), pred)\n",
    "ut.validate(aml, pred, jan_2021_target,.55)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC_LOW = 41 #41\n",
    "YC_LOW = 157 # 157\n",
    "XC_HIGH = 671# 671\n",
    "YC_HIGH = 373 #\n",
    "model = torch.load('pytorch_model')\n",
    "VARIABLES = ['temperature','salinity','u_east', 'v_north',  'w_north', 'w_east']\n",
    "nc = netCDF4.Dataset(ut.localize_nc_file('nor4km_data',2021, 1,20 ))\n",
    "data = ut.get_relevant_data_nc(nc,VARIABLES,12)\n",
    "plankton = netCDF4.Dataset(ut.localize_plankton_file('plankton_data', 2021, 1, 20))['Calanus_finmarchicus']\n",
    "#print(data.shape, plankton.shape)\n",
    "data = np.append(data, plankton, axis=0)\n",
    "grads = []\n",
    "for i in range(len(VARIABLES) +1):\n",
    "    grad = np.gradient(data[i,:,:])\n",
    "    grad = np.sqrt(np.square(grad[0].data) + np.square(grad[0].data))\n",
    "    grads.append(grad)\n",
    "#print(data.shape, np.array(grads).shape)\n",
    "data = np.append(data, grads, axis = 0)\n",
    "#data = np.reshape(data, (-1,14))\n",
    "#print(data.shape)\n",
    "#prediction = model(torch.tensor(data,dtype=torch.float32)).detach().numpy()\n",
    "#prediction = prediction.reshape(1,620,941)\n",
    "pred = np.zeros((620, 941))\n",
    "\n",
    "prediction_data = []\n",
    "[[prediction_data.append(data[:,yc, xc]) for yc in range(YC_LOW, YC_HIGH)]for xc in range(XC_LOW, XC_HIGH)]\n",
    "prediction_data = np.array(prediction_data)\n",
    "prediction_data= aml.predict(h2o.H2OFrame(prediction_data, column_names = names))\n",
    "i = 0\n",
    "prediction_data = prediction_data.as_data_frame().to_numpy()\n",
    "#[[pred[i,j] = model(torch.tensor(data[:,i,j],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for xc in range(XC_LOW, XC_HIGH):\n",
    "    if xc % 100 ==0: print(xc)\n",
    "    for yc in range(YC_LOW, YC_HIGH):\n",
    "        data = prediction_data[i]\n",
    "        #print(data)\n",
    "        pred[yc, xc] = prediction_data[i,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ut.get_relevant_data_nc(nc,VARIABLES,12)\n",
    "mask = data[0,...].mask\n",
    "pred = np.ma.masked_array(pred, mask)\n",
    "ut.print_on_map(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb3a25738bdf5b289ae80fb0d35cc87d4e1ad5c2988ca14163999442193168c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
